# =====================================================
# SOCIAL INSIGHT - PRODUCTION (Full Stack)
# =====================================================
# Run: docker-compose -f docker-compose.prod.yml up -d
# For AWS: Update .env.prod with RDS, ElastiCache endpoints
# =====================================================

services:
  # ===== INFRASTRUCTURE =====
  postgres:
    image: postgres:15-alpine
    container_name: social_insight_postgres_prod
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - "${DB_PORT}:5432"
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
      - ./infrastructure/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${DB_USER}" ]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - social_insight_prod
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: social_insight_zookeeper_prod
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - social_insight_prod
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: social_insight_kafka_prod
    depends_on:
      - zookeeper
    ports:
      - "${KAFKA_PORT}:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: [ "CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list" ]
      interval: 10s
      timeout: 10s
      retries: 10
    networks:
      - social_insight_prod
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: social_insight_redis_prod
    ports:
      - "${REDIS_PORT}:6379"
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - social_insight_prod
    restart: unless-stopped

  # ===== PROCESSING LAYER =====
  ml-service:
    build:
      context: .
      dockerfile: processing/ml-service/Dockerfile
    container_name: social_insight_ml_prod
    environment:
      - ML_PORT=${ML_PORT}
    ports:
      - "${ML_PORT}:${ML_PORT}"
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:${ML_PORT}/health').read()" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - social_insight_prod

  consumer:
    build:
      context: .
      dockerfile: processing/consumer/Dockerfile
    container_name: social_insight_consumer_prod
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ml-service:
        condition: service_healthy
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
      - CONSUMER_GROUP=${CONSUMER_GROUP}
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      - REDIS_ADDR=${REDIS_ADDR}
      - ML_SERVICE_URL=${ML_SERVICE_URL}
    restart: unless-stopped
    networks:
      - social_insight_prod

  # ===== PRESENTATION LAYER =====
  api-gateway:
    build:
      context: .
      dockerfile: presentation/api-gateway/Dockerfile
    container_name: social_insight_api_prod
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - API_PORT=${API_PORT}
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      - REDIS_ADDR=${REDIS_ADDR}
      - FRONTEND_DIR=./frontend
    ports:
      - "${API_PORT}:${API_PORT}"
    restart: unless-stopped
    networks:
      - social_insight_prod

  # ===== INGESTION LAYER =====
  hn-crawler:
    build:
      context: .
      dockerfile: ingestion/hn-crawler/Dockerfile
    container_name: social_insight_hn_crawler_prod
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
      - CRAWL_INTERVAL=${HN_CRAWL_INTERVAL}
    restart: unless-stopped
    networks:
      - social_insight_prod

  medium-crawler:
    build:
      context: .
      dockerfile: ingestion/medium-crawler/Dockerfile
    container_name: social_insight_medium_crawler_prod
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
      - CRAWL_INTERVAL=${MEDIUM_CRAWL_INTERVAL}
    restart: unless-stopped
    networks:
      - social_insight_prod

  devto-crawler:
    build:
      context: .
      dockerfile: ingestion/devto-crawler/Dockerfile
    container_name: social_insight_devto_crawler_prod
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BROKERS=${KAFKA_BROKERS}
      - KAFKA_TOPIC=${KAFKA_TOPIC}
      - CRAWL_INTERVAL=${DEVTO_CRAWL_INTERVAL}
    restart: unless-stopped
    networks:
      - social_insight_prod

volumes:
  postgres_data_prod:

networks:
  social_insight_prod:
    driver: bridge
