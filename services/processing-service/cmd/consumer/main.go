// =====================================================
// CONSUMER MAIN - Äá»c data tá»« Kafka â†’ Redis + PostgreSQL
// =====================================================
// MÃ´ táº£: Consumer Ä‘á»c posts tá»« Kafka
// LÆ°u vÃ o Redis (cache) vÃ  PostgreSQL (storage)
//
// CÃ¡ch cháº¡y: go run cmd/consumer/main.go
// =====================================================

package main

import (
	"context"
	"fmt"
	"os"
	"os/signal"
	"sync/atomic"
	"syscall"
	"time"

	"social-insight/config"
	"social-insight/internal/database"
	"social-insight/internal/kafka"
	"social-insight/internal/models"
	redisclient "social-insight/internal/redis"
)

// PostHandler xá»­ lÃ½ posts nháº­n tá»« Kafka
type PostHandler struct {
	redis     *redisclient.Client
	db        *database.DB
	batchSize int

	// Buffer Ä‘á»ƒ batch insert
	buffer []models.Post

	// Counter
	processedCount int64
}

// HandlePost xá»­ lÃ½ má»™t post
func (h *PostHandler) HandlePost(post models.Post) error {
	// 1. Cache vÃ o Redis (TTL 1 giá»)
	if err := h.redis.CachePost(post, time.Hour); err != nil {
		fmt.Printf("âš ï¸  Redis cache error: %v\n", err)
	}

	// 2. Cáº­p nháº­t counters trong Redis
	h.redis.IncrementCounter("posts:total")
	h.redis.IncrementCounter(fmt.Sprintf("posts:%s", post.Topic))
	h.redis.IncrementCounter(fmt.Sprintf("sentiment:%s", post.Sentiment))

	// 3. ThÃªm vÃ o recent posts
	h.redis.AddToRecentPosts(post)

	// 4. ThÃªm vÃ o buffer Ä‘á»ƒ batch insert
	h.buffer = append(h.buffer, post)

	// 5. Flush náº¿u Ä‘á»§ batch size
	if len(h.buffer) >= h.batchSize {
		if err := h.flush(); err != nil {
			return err
		}
	}

	atomic.AddInt64(&h.processedCount, 1)
	return nil
}

// flush lÆ°u buffer vÃ o PostgreSQL
func (h *PostHandler) flush() error {
	if len(h.buffer) == 0 {
		return nil
	}

	if err := h.db.InsertPosts(h.buffer); err != nil {
		return fmt.Errorf("batch insert error: %w", err)
	}

	fmt.Printf("ğŸ’¾ Saved %d posts to PostgreSQL\n", len(h.buffer))
	h.buffer = h.buffer[:0] // Clear buffer
	return nil
}

func main() {
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘     SOCIAL INSIGHT - DATA CONSUMER                         â•‘")
	fmt.Println("â•‘     Kafka â†’ Redis + PostgreSQL                             â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println()

	// Load config
	if err := config.LoadEnvFile(".env"); err != nil {
		fmt.Printf("âš ï¸  Warning: %v\n", err)
	}
	cfg, err := config.Load()
	if err != nil {
		fmt.Printf("âŒ Config error: %v\n", err)
		os.Exit(1)
	}
	cfg.Validate()
	cfg.LogConfig()

	// Context Ä‘á»ƒ graceful shutdown
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Báº¯t signal
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)

	// ====== BÆ¯á»šC 1: Káº¿t ná»‘i Redis ======
	fmt.Println("ğŸ“¡ Äang káº¿t ná»‘i Redis...")
	redisClient, err := redisclient.NewClient(cfg.RedisAddr)
	if err != nil {
		fmt.Printf("âŒ Lá»—i Redis: %v\n", err)
		os.Exit(1)
	}
	defer redisClient.Close()
	fmt.Println("âœ… ÄÃ£ káº¿t ná»‘i Redis")

	// ====== BÆ¯á»šC 2: Káº¿t ná»‘i PostgreSQL ======
	fmt.Println("ğŸ“¡ Äang káº¿t ná»‘i PostgreSQL...")
	db, err := database.NewDB(database.Config{
		Host:     cfg.PGHost,
		Port:     cfg.PGPort,
		User:     cfg.PGUser,
		Password: cfg.PGPassword,
		DBName:   cfg.PGDBName,
	})
	if err != nil {
		fmt.Printf("âŒ Lá»—i PostgreSQL: %v\n", err)
		os.Exit(1)
	}
	defer db.Close()
	fmt.Println("âœ… ÄÃ£ káº¿t ná»‘i PostgreSQL")

	// ====== BÆ¯á»šC 3: Táº¡o Handler ======
	handler := &PostHandler{
		redis:     redisClient,
		db:        db,
		batchSize: cfg.ConsumerBatchSize,
		buffer:    make([]models.Post, 0, cfg.ConsumerBatchSize),
	}

	// ====== BÆ¯á»šC 4: Táº¡o Kafka Consumer ======
	fmt.Println("ğŸ“¡ Äang káº¿t ná»‘i Kafka...")
	consumer, err := kafka.NewConsumer(
		cfg.KafkaBrokers,
		cfg.ConsumerGroup,
		cfg.KafkaTopic,
		handler,
	)
	if err != nil {
		fmt.Printf("âŒ Lá»—i Kafka: %v\n", err)
		os.Exit(1)
	}
	defer consumer.Close()
	fmt.Printf("âœ… ÄÃ£ subscribe topic: %s\n\n", cfg.KafkaTopic)

	// ====== BÆ¯á»šC 5: Báº¯t Ä‘áº§u consume ======
	fmt.Println("ğŸ‘‚ Äang láº¯ng nghe messages tá»« Kafka...")
	fmt.Println("   Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng")
	fmt.Println()

	// Goroutine Ä‘á»ƒ flush Ä‘á»‹nh ká»³
	go func() {
		ticker := time.NewTicker(cfg.ConsumerFlushInterval)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				handler.flush()
			}
		}
	}()

	// Goroutine Ä‘á»ƒ in stats Ä‘á»‹nh ká»³
	go func() {
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				count := atomic.LoadInt64(&handler.processedCount)
				fmt.Printf("ğŸ“Š Total processed: %d posts\n", count)
			}
		}
	}()

	// Goroutine Ä‘á»ƒ consume
	go func() {
		if err := consumer.Start(ctx); err != nil {
			fmt.Printf("âŒ Consumer error: %v\n", err)
		}
	}()

	// Äá»£i signal
	<-sigChan
	fmt.Println("\nâš ï¸  Nháº­n tÃ­n hiá»‡u dá»«ng, Ä‘ang shutdown...")

	// Cancel context
	cancel()

	// Flush remaining buffer
	handler.flush()

	// In káº¿t quáº£ cuá»‘i
	finalCount := atomic.LoadInt64(&handler.processedCount)
	dbCount, _ := db.GetPostCount()

	fmt.Println()
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘                     Káº¾T QUáº¢                                â•‘")
	fmt.Println("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
	fmt.Printf("â•‘  ğŸ“ Tá»•ng posts Ä‘Ã£ xá»­ lÃ½: %d\n", finalCount)
	fmt.Printf("â•‘  ğŸ’¾ Posts trong PostgreSQL: %d\n", dbCount)
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
}
